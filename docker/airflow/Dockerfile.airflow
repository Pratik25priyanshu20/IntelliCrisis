# Dockerfile.airflow

FROM apache/airflow:2.8.0

# Switch to root to install system packages
USER root

# Install Java (required for PySpark)
RUN apt-get update && \
    apt-get install -y default-jdk && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Set Java environment variables
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
ENV PATH=$PATH:$JAVA_HOME/bin

# Switch back to airflow user
USER airflow

# Install Python packages
RUN pip install --no-cache-dir \
    kafka-python==2.0.2 \
    pyspark==3.5.6 \
    delta-spark==3.0.0 \
    pymongo==4.6.1 \
    python-dotenv==1.0.0 \
    praw==7.7.0 \
    sentence-transformers \
    pydantic-settings

# Set Python path
ENV PYTHONPATH=/opt/airflow/project_kafka:/opt/airflow/config

# Default working directory
WORKDIR /opt/airflow